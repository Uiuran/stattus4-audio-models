{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \"source\": [\n",
    "    \"from src.model import *\\n\",\n",
    "    \"# In TensorFlow a device name is a string of the following form:\\n\",\n",
    "    \"#   /job:<name>/replica:<replica>/task:<task>/device:<type>:<device_num>\\n\",\n",
    "    \"#\\n\",\n",
    "    \"# <name> is a short identifier conforming to the regexp\\n\",\n",
    "    \"#     [a-zA-Z][_a-zA-Z]*\\n\",\n",
    "    \"# <type> is a supported device type (e.g. 'cpu' or 'gpu')\\n\",\n",
    "    \"# <replica>, <task>, <device_num> are small non-negative integers and are\\n\",\n",
    "    \"# densely allocated (except in tests).\\n\",\n",
    "    \"#\\n\",\n",
    "    \"# For some purposes, we also allow device patterns, which can specify\\n\",\n",
    "    \"# some or none of the specific fields above, with missing components,\\n\",\n",
    "    \"# or \\\"<component>:*\\\" indicating \\\"any value allowed for that component.\\n\",\n",
    "    \"#\\n\",\n",
    "    \"# For example:\\n\",\n",
    "    \"#   \\\"/job:param_server\\\"   - Consider any devices in the \\\"param_server\\\" job\\n\",\n",
    "    \"#   \\\"/device:cpu:*\\\"       - Consider any cpu devices in any job/task/replica\\n\",\n",
    "    \"#   \\\"/job:*/replica:*/task:*/device:cpu:*\\\"  - Consider any cpu devices in any\\n\",\n",
    "    \"#                                             job/task/replica\\n\",\n",
    "    \"#   \\\"/job:w/replica:0/task:0/device:gpu:*\\\"  - Consider any gpu devices in\\n\",\n",
    "    \"#                                             replica 0, task 0, of job \\\"w\\\"\"\n",
    "   ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"dataload = Sass('/home/penalvad/stattus4/test/', num_samples=5, number_of_batches=1, split_tax=.9, freq_size=480, time_size=640, same_data_validation=True)\\n\",\n",
    "    \"dataload_2 = Sass('/home/penalvad/stattus4/benchfull/', num_samples=7, number_of_batches=1, split_tax=.9, freq_size=600, time_size=80, same_data_validation=True)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"dtrain = dataload.training()\\n\",\n",
    "    \"dtrain_2 = dataload_2.training()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \"dtrain = dataload.training()\\n\",\n",
    "    \"dtest = dataload.testing()\\n\",\n",
    "    \"\\n\",\n",
    "    \"data_train = np.ndarray( shape=(14,600,80,3) )\\n\",\n",
    "    \"data_test = np.ndarray( shape=(8,600,50,3) )\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i in range(6):\\n\",\n",
    "    \"    \\n\",\n",
    "    \"  data_train[2*i,:,:,:] = dtrain[i][0][2]\\n\",\n",
    "    \"  data_train[2*i+1,:,:,:] = dtrain[i][1][2]\\n\",\n",
    "    \"\\n\",\n",
    "    \"#for i in range(4):\\n\",\n",
    "    \"\\n\",\n",
    "    \"  #data_test[2*i,:,:,0] = dtest[i][0][2]\\n\",\n",
    "    \"  #data_test[2*i+1,:,:,0] = dtest[i][1][2]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"# Architecture Basics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"colab_type\": \"text\",\n",
    "    \"id\": \"99BygeASuBJD\"\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"##  Gated CNN\\n\",\n",
    "    \"  Gated CNN is a doubled CNN in whom one of the convoluted signals does the role of opening/closing the network, giving an **Attention Mechanism** to the convolution, for being activated by a sigmoid.\\n\",\n",
    "    \"  It gives non-vanishing gradient, since the multiplication rule for the derivative applies, also, applies gradient to the linear convoluted part.\\n\",\n",
    "    \"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"### GCNN 2D\\n\",\n",
    "    \"  This unit uses sigmoid function in all frame pixels and do element-wise multiplication. Use it for images or time-series TF Features frame. The standard convolution mode is Valid. The output size of the convolution is given by:\\n\",\n",
    "    \" \\n\",\n",
    "    \" Padding Valid\\n\",\n",
    "    \"\\\\begin{align}\\n\",\n",
    "    \"dimemsion output size = \\\\ceil{ \\\\frac{dim size - (kernel dim size - 1)*dilation rate}{stride} }\\n\",\n",
    "    \"\\\\end{align} \\n\",\n",
    "    \"\\n\",\n",
    "    \"Where dilation rate is how may pixel are each filter spaced from each other, when dilation rate >= 1 then stride = 1 (since if you stride will be losing information from the data).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"#Cascading deepness networks mem size\\n\",\n",
    "    \"    \\n\",\n",
    "    \"def channeling_rule(channelin, filterlist):        \\n\",\n",
    "    \"  channellist = [channelin]\\n\",\n",
    "    \"  for filter in filterlist:\\n\",\n",
    "    \"    channellist.append(channellist[-1] + filter + 3)  \\n\",\n",
    "    \"\\n\",\n",
    "    \"  return channellist \"\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"# Label Vector Feed\\n\",\n",
    "    \"# dtrain[0][0][1]\\n\",\n",
    "    \"ltrain = []\\n\",\n",
    "    \"ltest = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i in range(14):    \\n\",\n",
    "    \"  ltrain.append([0,1])   \\n\",\n",
    "    \"  ltrain.append([1,0])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"#for i in range(4):\\n\",\n",
    "    \"  #ltest.append([0,1])    \\n\",\n",
    "    \"  #ltest.append([1,0])\"\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"for i in range(10):  \\n\",\n",
    "    \"  feed_dict[buildgraph.signal_in[i]] = data_train[:14,:,8*i:8*(i+1),:]\\n\",\n",
    "    \"\\n\",\n",
    "    \"feed_dict[buildgraph.label_tensor] = ltrain[:14]\\n\",\n",
    "    \"feed_dict[buildgraph.learning_rate] = 0.00001 \\n\",\n",
    "    \"\\n\",\n",
    "    \"output = buildgraph.run_cgraph(feed_dict, op_to_run = [buildgraph.namescopes['softmax'][-1].name, buildgraph.namescopes['softmax_3'][-1].name, buildgraph.namescopes['softmax_2'][-1].name, buildgraph.namescopes['softmax_4'][-1].name, buildgraph.namescopes['softmax_5'][-1].name, buildgraph.namescopes['softmax_6'][-1].name], number_of_runs = 40, mode = 'minimize', ckpt_dir_name='../ckpt/model', new_session=True, output_log = True, stop=0.4, adaptative_lr=True, verbose=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"#for i in range(10):  \\n\",\n",
    "    \"  #feed_dict[buildgraph.signal_in[i]] = data_train[:,:,5*i:5*(i+1),:]\\n\",\n",
    "    \"\\n\",\n",
    "    \"#feed_dict[buildgraph.l_vec] = ltrain[:14]\\n\",\n",
    "    \"#feed_dict[buildgraph.learning_rate] = 0.00001 \\n\",\n",
    "    \"\\n\",\n",
    "    \"#acc = buildgraph.run_cgraph(feed_dict, op_to_run = buildgraph.namescopes['reducemean'][-1].name, number_of_runs = 1, mode = 'x', new_session=True, output_log = True, auto_lr = False, verbose=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"#print('Tensor {}'.format(buildgraph.namescopes.gcnn2d_1[1].name))\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Recovering Model from .meta and .data. It uses .index and checkpoint to map variables and last checkpoint to the graph \\n\",\n",
    "graph = tf.Graph()\n",
    "    \n",
    "with graph.as_default():\n",
    "    \n",
    "    saver = tf.train.import_meta_graph(\\\"../ckpt/model.meta\\\", import_scope='')\n",
    "    feed_dict = {}\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "    Restore variables from disk.\n",
    "    \"    \\n\",\n",
    "    \"    saver.restore(sess, tf.train.latest_checkpoint('../ckpt/') )    \\n\",\n",
    "    \"    feed_dict[sess.graph.get_tensor_by_name('signal_in:0')] = data_train[:14,:,:8,:]\\n\",\n",
    "    \"    for i in np.arange(1,10):  \\n\",\n",
    "    \"      feed_dict[sess.graph.get_tensor_by_name('signal_in_'+str(i)+':0')] = data_train[:14,:,8*i:8*(i+1),:]\\n\",\n",
    "    \"    feed_dict[sess.graph.get_tensor_by_name('losscrossentropy/labels:0')] = ltrain[:14]\\n\",\n",
    "    \"    feed_dict[sess.graph.get_tensor_by_name('learning_rate:0')] = 0.0001      \\n\",\n",
    "    \"  #for op in graph.get_operations():\\n\",\n",
    "    \"    #print(2*'\\\\n')\\n\",\n",
    "    \"    #print(op.name)  \\n\",\n",
    "    \"    minimize_op = sess.graph.get_operation_by_name('losscrossentropy/Adam')\\n\",\n",
    "    \"    loss = sess.graph.get_tensor_by_name('losscrossentropy/categorical_crossentropy/weighted_loss/value:0')\\n\",\n",
    "    \"    acc = sess.graph.get_tensor_by_name('reducemean/Mean:0')\\n\",\n",
    "    \"    for i in range(400):\\n\",\n",
    "    \"      lossval,_ = sess.run([loss,minimize_op], feed_dict=feed_dict)\\n\",\n",
    "    \"      accval = sess.run([acc], feed_dict=feed_dict)\\n\",\n",
    "          if lossval < 0.3:\\n\",\n",
    "            saver.save(sess, '../ckpt/model2')\\n\",\n",
    "            print('\\\\n')\\n\",\n",
    "            print('saving')\\n\",\n",
    "            print('\\\\n')\\n\",\n",
    "            \\n\",\n",
    "          print('loss ',lossval)     \\n\",\n",
    "          print('acc ', accval)\\n\",\n",
    "          print(2*'\\\\n')\\n\",\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
